= Building LISP
Leo Howel <leo@lwh.jp>
v1.0, 2021-01-16
:doctype: book
:sectnums:
:sectnumlevels: 5
:partnums:
:toc: right

:sectnums!:
== Contents
<<Introduction,Chapter 1: Introduction>>

<<Data,Chapter 2: Data>>

<<Parser,Chapter 3: Parser>>

<<Expressions,Chapter 4: Expressions>>

<<Built-in functions,Chapter 5: Built-in functions>>

<<Arithmetic,Chapter 6: Arithmetic>>

<<Lambda expressions and closures,Chapter 7: Lambda expressions and closures>>

<<Booleans and short-circuit evaluation,Chapter 8: Booleans and short-circuit evaluation>>

<<Syntactic sugar,Chapter 9: Syntactic sugar>>

<<Variadic functions,Chapter 10: Variadic functions>>

<<Macros,Chapter 11: Macros>>

<<Library,Chapter 12: Library>>

<<Quasiquotation,Chapter 13: Quasiquotation>>

<<Continuations and tail recursion,Chapter 14: Continuations and tail recursion>>

<<Garbage collection,Chapter 15: Garbage collection>>

<<Where do we go from here?,Chapter 16: Where do we go from here?>>

Questions? Comments? Email leo@lwh.jp.

== Copyright
This document is Copyright (c) by Leo W. Howell.
All rights reserved.

The code is Copyright (c) 2021 by Leo W. Howell and Michael D. Henderson.
The code is released under the MIT License.

This document was copied from the https://www.lwh.jp/lisp/index.html[original] and converted to AsciiDoc on 2021-01-16.

I converted the C code to Go and created directories and packages to match the chapter-by-chapter progress of the code.

Please file an issue with the https://github.com/mdhender/lisp[GitHub repository] if you find any errors with my transcription.

== Introduction
The best way to understand how something works is to try to build it for yourself. Reading somebody else's explanation might satisfy your curiosity, but without the experience of falling into all the little traps it is difficult to get a feel for why something is designed a certain way.

It's been said that every would-be programmer should write a compiler. While I think this is good advice (although I haven't followed it myself), there is so much effort involved just in parsing a language such as C that any potential insights risk getting lost in a mire of details. Perhaps creating an interpreter for some simple language would be a good first step.

I first started playing around with LISP a good few years ago, yet much later than I should have. This led me to the classic lecture series http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/[Structure and Interpretation of Computer Programs]. If you have the next 24 hours free and haven't seen the videos already, go watch them now.

The course covers many topics, but the second half shows in detail how to evaluate LISP, first by implementing a simple version of eval in LISP itself. I figured that this would translate well into C, and so decided to try creating my own implementation of LISP.

It was really easy.

This article is an attempt to share the process by which I built my implementation, and the chapters occur roughly in the order in which I did things. Why not follow along and create your own version in your language of choice?
footnote:[If you are using a fancy language which supports something like eval, it would be cool to expose the native datatypes to the LISP environment.]

As a professional programmer (ha, ha), I spend the majority of my time writing C and C++. Most of the rest is Java. There are many languages out there, each with their own debatable merits, but I'd like to demonstrate just how simple a LISP machine can be â€” even built in as low-level a language as C. See John McCarthy's http://www-formal.stanford.edu/jmc/history/lisp/lisp.html[History of LISP] for the story of the pioneers.

So here is my toy implementation of LISP. I've borrowed features from various dialects, but it's closer to Scheme than Common LISP. The differences are trivial enough that changing over would not require substantial changes to the interpreter. Don't worry if you're not familiar with LISP; I will define everything as I go along.

It is not meant to be the smallest possible implementation, nor the most efficient, nor the most complete; it could however be described as lazy. My goal was to write robust, easy-to-read code that does exactly what it needs to, and no more, and I hope that it conveys how little effort is required to construct an incredibly powerful environment like LISP.

== Data
We will define four kinds of object to begin with:

Integer::
A number. For example: 3, -9, 0.
Symbol::
A name consisting of a string of characters. For example: `FOO`, `BAR`, `ADD-TWO`. The names are case-sensitive, so `foo`, `Foo`, and `FOO` are three distinct symbols.
NIL::
Represents "nothing". A bit like `nil` in Go and other languages.
Pair::
A pair consists of two elements, which for historical reasons are called *car* and *cdr*. Both can hold either an integer, a symbol, `NIL`, or a reference to another pair. The types of each element may be different.

Integers, symbols and NIL are called simple data. The term *atom* can refer to either a simple datum or a pair (purists may disagree on this point).

Note that integers and symbols are immutable, so we can think of two integers with the same value as being the same object. This is particularly useful for symbols, because it allows us to test for equality by comparing pointers.

=== Implementation
Let's declare some types to hold our data. There are many clever ways to store LISP objects efficiently, but for this implementation we will stick to a very simple scheme [please excuse the pun].

[source,go]
----
type AtomKind int
const ( // enums for AtomKind
	AtomKind_NIL AtomKind = iota
	AtomKind_Pair
	AtomKind_Symbol
	AtomKind_Integer
)

type Atom struct {
	kind    AtomKind
    integer int64
    pair    *Pair
    symbol  []byte
}

type Pair struct {
	atom [2]Atom
}
----

A few helper functions will be handy.

[source,go]
----
// nilp is a predicate that returns true if the argument is NIL.
func nilp(a Atom) bool { return a.kind == AtomKind_NIL }
----

The "p" in `nilp` stands for "predicate". Identifiers in Go may not contain question marks. There is no need to restrict our LISP implementation in that way, of course.

[source,go]
----
// car returns the car of a pair. panics if p is not a pair.
func car(p Atom) Atom { return p.pair.atom[0] }

// cdr returns the cdr of a pair. panics if p is not a pair.
func cdr(p Atom) Atom { return p.pair.atom[1] }
----

Integers and (pointers to) strings can be copied around, but we need to allocate pairs on the heap.

[source,go]
----
func cons(car, cdr Atom) Atom {
	return Atom{kind: AtomKind_Pair, pair: &Pair{atom: [2]Atom{car, cdr}}}
}
----

`cons` is a function to allocate a pair on the heap and assign its two elements.

At this point you will have noticed that using `cons` will leak memory the moment its return value is discarded. Go is a garbage-collected language, so this is not a problem for our implementation. (Note that a faster/smarter/different implementation would want to avoid allocating and collecting atoms, so it might implement a memory pool for atoms.)

Now we can start creating LISP objects. An integer:

[source,go]
----
func make_int(x int64) Atom {
	return Atom{kind: AtomKind_Integer, integer: x}
}
----

And a symbol:

[source,go]
----
func make_sym(s []byte) Atom {
	a := Atom{kind: AtomKind_Symbol, symbol: make([]byte, len(s), len(s))}
	copy(a.symbol, s)
	return a
}
----

We create a duplicate of the symbol value here so that the caller doesn't have to worry about managing buffers.

=== Testing

[source,go]
----
func TestMakeInt(t *testing.T) {
	for _, tt := range []struct {
		name    string
		integer int64
	}{
		{"a", 42},
	} {
		a := make_int(tt.integer)
		if !(a.kind == AtomKind_Integer) {
			t.Errorf("%s: expected AtomKind_Integer: got %d\n", tt.name, a.kind)
		}
		if !(tt.integer == a.integer) {
			t.Errorf("%s: expected %d: got %d\n", tt.name, tt.integer, a.integer)
		}
	}
}

func TestMakeSym(t *testing.T) {
	for _, tt := range []struct {
		name   string
		symbol string
	}{
		{"snake", "snake"},
	} {
		s := []byte(tt.symbol)
		a := make_sym(s)
		if !(a.kind == AtomKind_Symbol) {
			t.Errorf("%s: expected AtomKind_Symbol: got %d\n", tt.name, a.kind)
		}
		if !bytes.Equal(s, a.symbol) {
			t.Errorf("%s: expected %q: got %q\n", tt.name, tt.symbol, string(a.symbol))
		}
	}
}
----

=== Textual representation
We will write a pair like this:

[source,lisp]
----
(a . b)
----

where `a` is the car and `b` is the cdr.

By using the `cdr` of a pair to reference another pair, we can create a chain:

[source,lisp]
----
(a . (b . (c . (d . NIL))))
----

Notice that the `cdr` of the last pair is `NIL`. This signifies the end of the chain, and we call this structure a *list*. To avoid having to write a large number of brackets, we will write the previous list like this:

[source,lisp]
----
(a b c d)
----

Finally, if the `cdr` of the last pair in a list is not NIL, we will write this:
[source,lisp]
----
(p q . r)
----
which is equivalent to
[source,lisp]
----
(p . (q . r))
----
This is called an improper list.

=== Implementation
Printing an atom or list is simple.

[source,go]
----
func print_expr(a Atom) {
	fmt.Printf("%s", a.String())
}
----

By using recursion we can print arbitrarily complex data structures. (Actually that's not true: for a very deeply nested structure we will run out of stack space, and a self-referencing tree will never finish printing).

[source,go]
----
func (a Atom) String() string {
	switch a.kind {
	case AtomKind_NIL:
		return "NIL"
	case AtomKind_Integer:
		return fmt.Sprintf("%d", a.integer)
	case AtomKind_Symbol:
		return string(a.symbol)
	case AtomKind_Pair:
		sb := strings.Builder{}
		sb.WriteString("(")
		sb.WriteString(car(a).String())
		a = gcdr(a)
		for !nilp(a) {
			if a.kind != AtomKind_Pair {
				sb.WriteString(" . ")
				sb.WriteString(a.String())
				break
			}
			sb.WriteString(" ")
			sb.WriteString(car(a).String())
			a = gcdr(a)
		}
		sb.WriteString(")")
		return sb.String()
	}
	panic(fmt.Sprintf("assert(atom.kind %= %d)", a.kind))
}
----

=== Testing
See what print_expr does with various atoms:

|===
|Case|Atom|Output

|a|make_int(42)|42
|b|make_sym("FOO")|FOO
|c|cons(make_sym("X"), make_sym("Y"))|(X . Y)
|d|cons(make_int(1),cons(make_int(2),cons(make_int(3),nil)))|(1 2 3)
|===

[source,go]
----
func TestStringer(t *testing.T) {
	for _, tt := range []struct {
		name   string
		atom   Atom
		expect string
	}{
		{"a", make_int(42), "42"},
		{"b", make_sym([]byte("FOO")), "FOO"},
		{"c", cons(make_sym([]byte("X")), make_sym([]byte("Y"))), "(X . Y)"},
		{"d", cons(make_int(1), cons(make_int(2), cons(make_int(3), Atom{}))), "(1 2 3)"},
	} {
		a := tt.atom.String()
		if tt.expect != a {
			t.Errorf("%s: expected %q: got %q\n", tt.name, tt.expect, a)
		}
	}
}
----

All this is pretty trivial. We'll get on to some more interesting stuff in the next chapter.

=== One last thing
Remember we said that we would treat identical symbols as being the same object? We can enforce that by keeping track of all the symbols created, and returning the same atom if the same sequence of characters is requested subsequently.

Languages with a set or hashtable container make this easy, but we can use the LISP data structures already implemented to store the symbols in a list:

[source,go]
----
var sym_table Atom

func make_sym(s []byte) Atom {
	for p := sym_table; !nilp(p); p = cdr(p) {
		if bytes.Equal(car(p).symbol, s) {
			return car(p)
		}
	}
	a := Atom{kind: AtomKind_Symbol, symbol: make([]byte, len(s), len(s))}
	copy(a.symbol, s)
	sym_table = cons(a, sym_table)
	return a
}
----

Neat, huh? It's not particularly efficient, but it will do fine for now.

== Parser
The next stage in our project is parsing: taking a line of text from the user (or elsewhere), and creating the data objects it represents. Naturally the user might type something which does not represent an object according to our definitions, in which case we must have some way to signal an error.

=== Errors
Here is a definition of an Error type:

[source,go]
----
var ErrorEOF = errors.New("end-of-input")
var ErrorSyntax = errors.New("syntax error")
----

If, like me, you learned to program in BASIC on microcomputers, you will be familiar with the dreaded SYNTAX ERROR. Now is our chance to see things from the other side of the fence. Most of our functions from now on will return an Error to indicate whether and how something went wrong.

=== Lexer
I have no formal training in CS, but as far as I understand it the idea is to split a string up into tokens, which are both "words" and "punctuation", and discard any insignificant white space. So if the input is:

[source,lisp]
----
(foo bar)
----

Then the four tokens are `(`, `foo`, `bar`, and `)`.

So let's start by creating a lexer, which will return a slice containing the next token in a buffer.

[source,go]
----
// lex returns the next token along with the remaining input.
// it returns end-of-input if there is no input left to read.
func lex(input []byte) (token []byte, rest []byte, err error) {
	// skip leading whitespace
	input = bytes.TrimLeft(input, " \t\n")
	// return an error if no more input is left
	if len(input) == 0 {
		return nil, nil, ErrorEOF
	}
	// accept an open or close paren
	if input[0] == '(' || input[0] == ')' {
		return input[:1], input[1:], nil
	}
	// otherwise return all characters up to the first delimiter
	offset := bytes.IndexAny(input, "() \t\n")
	return input[:offset], input[offset:], nil
}
----
If our lexer hits the end of the string without finding a token (ie, the remainder of the string is entirely white space), it will return nil values for the token and remaining input. It will also return an error indicating end of input.

=== Parser
Now we can think about the parser itself. The entry point is read_expr, which will read a single (possibly complex) object and return the error status and a pointer to the remainder of the input.

[source,go]
----
func read_expr(input []byte) (a Atom, rest []byte, err error) {}
----

We know that expressions will be treated as lists, so we need another helper function to set the `cdr` on a pair. We'll call it `scdr`, for "set cdr." (Later we'll introduce a similar function for the `car`.)

[source,go]
----
// scdr set the cdr of a pair. panics if p is not a pair.
func scdr(p, a Atom) { p.pair.atom[1] = a }
----

We will first deal with the simple data: integers, symbols and `NIL`. If you have a regex library available then this is easy, but it's not too bad in plain Go either.

[source,go]
----
func parse_simple(input []byte) (a Atom, rest []byte, err error) {
	if token, rest := parse_integer(input); token != nil {
		i, err := strconv.ParseInt(string(token), 10, 0)
		return make_int(i), rest, err
	}
	if token, rest := parse_symbol(input); token != nil {
		if bytes.Equal(token, []byte("NIL")) {
			return Atom{}, rest, nil
		}
		return make_sym(token), rest, nil
	}
	panic("!")
}

func parse_integer(input []byte) (token, rest []byte) {
	lenToken := 0
	for lenToken < len(input) {
		r, w := utf8.DecodeRune(input[lenToken:])
		if unicode.IsDigit(r) {
			lenToken += w
		} else if lenToken == 0 && r == '+' {
			lenToken += w
		} else if lenToken == 0 && r == '-' {
			lenToken += w
		} else {
			break
		}
	}
	if lenToken == 0 || (lenToken == 1 && (input[0] == '+' || input[0] == '-')) {
		return nil, input
	}
	return input[:lenToken], input[lenToken:]
}

func parse_symbol(input []byte) (token, rest []byte) {
	lenToken := 0
	for lenToken < len(input) {
		r, w := utf8.DecodeRune(input[lenToken:])
		if unicode.IsLetter(r) {
			lenToken += w
		} else if unicode.IsSpace(r) {
			break
		} else if r == '+' || r == '-' || r == '_' {
			lenToken += w
		} else {
			break
		}
	}
	if lenToken == 0 || (lenToken == 1 && (input[0] == '+' || input[0] == '-')) {
		return nil, input
	}
	return input[:lenToken], input[lenToken:]
}
----

Notice two things: first, we are implementing a case-sensitive LISP, which is not the traditional behaviour. Secondly, `NIL` is a special case: it's parsed directly as AtomType_Nil, rather than leaving it as a symbol.

If you're familiar with the various dialects of LISP then you will know that `NIL` is not necessarily the same as `()`, the empty list. We could choose to treat `NIL` as a symbol which evaluates to itself, but for this project we will consider both representations to be exactly the same.

Next up are lists (including improper lists and pairs). The simplified list syntax makes this a little complicated, so we'll stick it all in a helper function. Once again recursion allows us to deal with nested lists.

[source,go]
----
// read_list returns a list. it assumes that it is called
// immediately after an opening paren is read in.
// it will read both proper and improper lists.
func read_list(input []byte) (a Atom, rest []byte, err error) {
	var result, tail, item Atom
	for {
		// read a token from the input in the hope that it will
		// be ')' or '.', which we can immediately handle.
		if token, rest, err := lex(input); err != nil {
			return Atom{}, rest, err
		} else if token[0] == ')' {
			// found the end of the list
			return result, rest, nil
		} else if token[0] == '.' && len(token) == 1 {
			// a single dot signals an improper (a/k/a dotted) list,
			// but it must not be the first thing in the list!
			if nilp(tail) {
				return Atom{}, token, ErrorSyntax
			}
			if item, rest, err = read_expr(rest); err != nil {
				return Atom{}, rest, err
			}
			// append to the result
			scdr(tail, item)
			// expect a closing paren
			token, rest, err = lex(rest)
			if err != nil || len(token) == 0 || token[0] != ')' {
				return Atom{}, rest, ErrorSyntax
			}
			return result, rest, nil
		}

		// ignore the token we just lexed and pass the entire input
		// buffer in to read the next expression. we have to because
		// that token could have started a list.
		item, rest, err = read_expr(input)
		if err != nil {
			return Atom{}, rest, err
		} else if nilp(tail) {
			// first item
			result = cons(item, Atom{})
			tail = result
		} else {
			scdr(tail, cons(item, Atom{}))
			tail = cdr(tail)
		}

		// make the rest of the input available for the next loop
		input = rest
	}
}
----

I dislike writing infinite loops, but this is the clearest layout I have come up with so far. Let me know if you can write a better one!

Finally we have `read_expr` itself, which is very simple now that we have done all of the hard work:

[source,go]
----
// read_expr reads the next expression from the input.
// that can be an atom, list, or NIL.
func read_expr(input []byte) (a Atom, rest []byte, err error) {
	token, rest, err := lex(input)
	if err != nil {
		return Atom{}, rest, err
	} else if token[0] == '(' {
		return read_list(rest)
	} else if token[0] == ')' {
		return Atom{}, rest, ErrorSyntax
	}
	// the parser wants to see only the current token and we
	// want to ensure that it parsed the entire token.
	a, excess, err := parse_simple(token)
	if len(excess) != 0 {
		// if we get here, there's a problem with the lex function.
		panic("assert(parse(token) should consume entire token)")
	}
	return a, rest, err
}
----
The check for a closing bracket will catch invalid forms such as `)` and `(X .)`.

There is some weirdness with the check for `excess` at the end. The `lex` function should return a single token; if the parse doesn't consume all of that token, then our lexer is broken. It shouldn't return that excess.

=== Testing
Go has a built-in test package, which we use to check that input is parsed correctly.

==== Lexer
[source,go]
----
func TestLex(t *testing.T) {
	for _, tt := range []struct {
		name   string
		input  string
		expect []string
		err    error
	}{
		{"a", "(foo bar)", []string{"(", "foo", "bar", ")"}, ErrorEOF},
		{"b", " ( ) ", []string{"(", ")"}, ErrorEOF},
		{"c", " ", []string{}, ErrorEOF},
	} {
		input := []byte(tt.input)
		var tokens [][]byte
		for len(input) != 0 {
			token, rest, err := lex(input)
			if err != nil {
				if tt.err == nil {
					t.Errorf("%s: unexpected error: %+v\n", tt.name, err)
				} else if !errors.Is(err, tt.err) {
					t.Errorf("%s: expected %+v: got %+v\n", tt.name, tt.err, err)
				}
				break
			}
			tokens = append(tokens, token)
			input = rest
		}
		if len(tt.expect) != len(tokens) {
			t.Errorf("%s: expected %d tokens: got %d\n", tt.name, len(tt.expect), len(tokens))
		}
		var got, expect [][]byte
		if len(tokens) < len(tt.expect) {
			got = make([][]byte, len(tt.expect), len(tt.expect))
			expect = make([][]byte, len(tt.expect), len(tt.expect))
		} else {
			got = make([][]byte, len(tokens), len(tokens))
			expect = make([][]byte, len(tokens), len(tokens))
		}
		for i, tok := range tt.expect {
			expect[i] = []byte(tok)
		}
		for i, tok := range tokens {
			got[i] = tok
		}
		for i := range expect {
			if expect[i] == nil {
				t.Errorf("%s: token %d: expected nil: got %q\n", tt.name, i, string(got[i]))
			} else if got[i] == nil {
				t.Errorf("%s: token %d: expected %q: got nil\n", tt.name, i, string(expect[i]))
			} else if !bytes.Equal(expect[i], got[i]) {
				t.Errorf("%s: token %d: expected %q: got %q\n", tt.name, i, string(expect[i]), string(got[i]))
			}
		}
	}
}
----

==== Parser
[source,go]
----
func TestParseInteger(t *testing.T) {
	for _, tt := range []struct {
		name  string
		input string
		token string
		rest  string
	}{
		{"a", "(foobar)", "", "(foobar)"},
		{"b", "42)", "42", ")"},
		{"c", "-42)", "-42", ")"},
		{"d", "+42)", "+42", ")"},
		{"e", "+foobar", "", "+foobar"},
	} {
		token, rest := parse_integer([]byte(tt.input))
		if tt.token != string(token) {
			t.Errorf("%s: expected token %q: got %q\n", tt.name, tt.token, string(token))
		}
		if tt.rest != string(rest) {
			t.Errorf("%s: expected rest %q: got %q\n", tt.name, tt.rest, string(rest))
		}
	}
}

func TestParseSymbol(t *testing.T) {
	for _, tt := range []struct {
		name  string
		input string
		token string
		rest  string
	}{
		{"a", "(foo bar)", "", "(foo bar)"},
		{"b", "foo bar)", "foo", " bar)"},
		{"c", " bar)", "", " bar)"},
		{"d", "bar)", "bar", ")"},
		{"e", ")", "", ")"},
	} {
		token, rest := parse_symbol([]byte(tt.input))
		if tt.token != string(token) {
			t.Errorf("%s: expected token %q: got %q\n", tt.name, tt.token, string(token))
		}
		if tt.rest != string(rest) {
			t.Errorf("%s: expected rest %q: got %q\n", tt.name, tt.rest, string(rest))
		}
	}
}
----

==== Read
For the reader, here's what our sample input looks like:
|===
|Case|Input|Output

|a|42|42
|b|(foo bar)|(FOO BAR)
|c|(s (t . u) v . (w . NIL))|(S (T . U) V W)
|d|()|NIL
|===

The table in our test function has some additional data (`rest` and `err`) so that we can add tests to catch syntax errors in the future. I actually used those when I was debugging the parser.

[source,go]
----
func TestRead(t *testing.T) {
	for _, tt := range []struct {
		name   string
		input  string
		expect string
		rest   string
		err    error
	}{
		{"a", "42", "42", "", nil},
		{"b", "(foo bar)", "(foo bar)", "", nil},
		{"c", " ( foo  bar ) ", "(foo bar)", " ", nil},
		{"d", "( s (t . u) v . (w . NIL))(foo)", "(s (t . u) v w)", "(foo)", nil},
		{"e", "()", "NIL", "", nil},
	} {
		a, rest, err := read_expr([]byte(tt.input))
		if err != nil {
			if tt.err == nil {
				t.Errorf("%s: unexpected error: %+v\n", tt.name, err)
			} else if !errors.Is(err, tt.err) {
				t.Errorf("%s: expected %+v: got %+v\n", tt.name, tt.err, err)
			}
			continue
		}
		if got := a.String(); tt.expect != got {
			t.Errorf("%s: expected %q: got %q\n", tt.name, tt.expect, got)
		}
		if tt.rest != string(rest) {
			t.Errorf("%s: expected rest %q: got %q\n", tt.name, tt.rest, string(rest))
		}
	}
}
----

Looks good! Remember that `()` is exactly the same as `NIL`, and that `(X Y)` is just another way of writing `(X . (Y . NIL))`.

== Expressions

== Built-in functions

== Arithmetic

== Lambda expressions and closures

== Booleans and short-circuit evaluation

== Syntactic sugar

== Variadic functions

== Macros

== Library

== Quasiquotation

== Continuations and tail recursion

== Garbage collection

== Where do we go from here?
